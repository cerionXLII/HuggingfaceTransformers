{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace Transformers\n",
    "This notebook will use the Hugging Face API to interact with different Transformer achitectures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 629/629 [00:00<00:00, 315kB/s]\n",
      "model.safetensors: 100%|██████████| 268M/268M [00:02<00:00, 116MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 24.0kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.27MB/s]\n"
     ]
    }
   ],
   "source": [
    "#Create instance of the sentiment analysis pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998427629470825},\n",
       " {'label': 'NEGATIVE', 'score': 0.9979380965232849}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = [\"You are such a nice person\", \"You are so lazy, you should really do something good for the world instead\"]\n",
    "classifier(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of the classifier pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'You should do one more repetition, you can do it!',\n",
       " 'labels': ['training', 'education', 'cooking', 'politics'],\n",
       " 'scores': [0.8017725348472595,\n",
       "  0.16816730797290802,\n",
       "  0.02121736854314804,\n",
       "  0.008842849172651768]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"You should do one more repetition, you can do it!\"\n",
    "candidate_labels = [\"politics\", \"training\", \"education\", \"cooking\"]\n",
    "\n",
    "classifier(input, candidate_labels=candidate_labels,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!',\n",
       " 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'],\n",
       " 'scores': [0.5036354064941406,\n",
       "  0.4787999987602234,\n",
       "  0.012600099667906761,\n",
       "  0.0026557904202491045,\n",
       "  0.0023087533190846443]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "oracle = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "oracle(\n",
    "    \"I have a problem with my iphone that needs to be resolved asap!!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I would like to know the meaning of life. The meaning of life is my responsibility. Your life is of course different from mine. But if you have this responsibility, and you understand your responsibility, why shouldn't we care for you? You are already one of my children. I would try to help you so that you can have a normal life, and I would like for you to go to school and work, and also learn English so that that you could have a better life. I wish that you might see your teacher someday. Now. I would like to talk about some things I noticed over the preceding couple of weeks about my parents, and whether or not I wanted to come back home to my parents and work in the field. I also wanted to say something about my sisters, who are pretty amazing. They were already older than me, and very happy and kind and beautiful, and I could ask them if they love how they are. So, for this particular day, the last time she saw me, she said that she was going to take me to get to know her sister and I couldn't attend. I don't mean that she said everything happened all that bad, I mean like she gave me a little hug, but she said she knew I hadn't seen anybody since. I think she thought I could go into recovery and it would come up a little bit more. Because she said that she just wished that I was with her and that she would be there\"}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Hello, I would like to know the meaning of life. The meaning of life is\"\n",
    "generator(prompt, max_length=142, num_return_sequences=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\cerion\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\pipelines\\token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.87922454,\n",
       "  'word': 'Pluto',\n",
       "  'start': 16,\n",
       "  'end': 21},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9412043,\n",
       "  'word': 'Pildammarna',\n",
       "  'start': 56,\n",
       "  'end': 67},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9957456,\n",
       "  'word': 'Malmö',\n",
       "  'start': 71,\n",
       "  'end': 76}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pipeline(\"ner\", grouped_entities=True)\n",
    "text = 'My dog is named Pluto, and he wants to play in the park Pildammarna in Malmö'\n",
    "\n",
    "model(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
